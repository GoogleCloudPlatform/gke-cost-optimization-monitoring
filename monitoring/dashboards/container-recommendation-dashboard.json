{
  "category": "CUSTOM",
  "displayName": "GKE Container Recommendations ",
  "mosaicLayout": {
    "columns": 12,
    "tiles": [
      {
        "height": 6,
        "widget": {
          "timeSeriesTable": {
            "dataSets": [
              {
                "tableDisplayOptions": {},
                "timeSeriesQuery": {
                  "timeSeriesQueryLanguage": "# Get all workloads using horizontal pod autoscaling(HPA)\ndef all_hpa_workloads =\n  { hpa_cpu:\n      fetch k8s_pod\n      | metric 'custom.googleapis.com/podautoscaler/hpa/cpu/target_utilization'\n      | group_by\n          [resource.project_id, resource.location, resource.cluster_name,\n           resource.namespace_name, controller_name: metric.targetref_name,\n           controller_type: metric.targetref_kind]\n  ; hpa_memory:\n      fetch k8s_pod\n      | metric\n          'custom.googleapis.com/podautoscaler/hpa/memory/target_utilization'\n      | group_by\n          [resource.project_id, resource.location, resource.cluster_name,\n           resource.namespace_name, controller_name: metric.targetref_name,\n           controller_type: metric.targetref_kind] }\n  | outer_join 1, 1\n  | value [has_value: 1];\n\n# Filter out workloads using HPA \ndef workloads_without_hpa =\n  { hpa: @all_hpa_workloads\n  ; workloads:\n      fetch 'k8s_container' :: 'kubernetes.io/container/cpu/request_cores'\n      | group_by\n          [resource.project_id, resource.location, resource.cluster_name,\n           resource.namespace_name,\n           controller_name: metadata.system_labels.top_level_controller_name,\n           controller_type: metadata.system_labels.top_level_controller_type]\n      | value [has_value: 1] }\n  | outer_join 0\n  | filter ((hpa.has_value + workloads.has_value) == 1);\n\n# Get the CPU request cores\ndef current_cpu_request = \nfetch k8s_container::kubernetes.io/container/cpu/request_cores\n  | group_by\n      [container: resource.container_name, resource.project_id, resource.location, resource.cluster_name,\n       resource.namespace_name, container_name: resource.container_name,\n       controller_name: metadata.system_labels.top_level_controller_name,\n       controller_type: metadata.system_labels.top_level_controller_type], 1d, .mean\n       | mul(1000);\n      \n\n# Get the CPU limit cores\ndef current_cpu_limit = \nfetch k8s_container::kubernetes.io/container/cpu/limit_cores\n|group_by [container: resource.container_name, resource.project_id, resource.location, resource.cluster_name,\n       resource.namespace_name, container_name: resource.container_name,\n       controller_name: metadata.system_labels.top_level_controller_name,\n       controller_type: metadata.system_labels.top_level_controller_type], 1d, .mean | mul(1000);\n\n# Get the CPU request core recommendation 95th percentile (QoS: burstable and best effort) \ndef cpu_request_recommendation = \nfetch k8s_scale ::\n    kubernetes.io/autoscaler/container/cpu/per_replica_recommended_request_cores\n  | group_by\n      [container: metric.container_name, resource.project_id,\n       resource.location, resource.cluster_name, resource.namespace_name,\n       resource.controller_kind, controller_name: resource.controller_name], sliding(14d),\n    [cpu_request_recommendation:\n       percentile(value.per_replica_recommended_request_cores, 95) * 1000]\n       ;\n\n# Get the CPU request core recommendation mean (QoS: guaranteed)\ndef guaranteed_cpu_request_recommendation = \nfetch k8s_scale ::\n    kubernetes.io/autoscaler/container/cpu/per_replica_recommended_request_cores\n  | group_by\n      [container: metric.container_name, resource.project_id,\n       resource.location, resource.cluster_name, resource.namespace_name,\n       resource.controller_kind, controller_name: resource.controller_name], sliding(14d), .mean \n       | mul(1000);\n\n# Get the number of containers\ndef container_count = \nfetch k8s_container:: kubernetes.io/container/cpu/request_cores\n  | group_by\n      [container: resource.container_name,resource.project_id, resource.location, resource.cluster_name,\n       resource.namespace_name, container_name: resource.container_name,\n       controller_name: metadata.system_labels.top_level_controller_name,\n       controller_type: metadata.system_labels.top_level_controller_type], 1m,[row_count: row_count()] ;\n\n#Get the requested memory bytes \ndef current_memory_request = \nfetch k8s_container::kubernetes.io/container/memory/request_bytes\n| group_by\n      [container: resource.container_name,resource.project_id, resource.location, resource.cluster_name,\n       resource.namespace_name, container_name: resource.container_name,\n       controller_name: metadata.system_labels.top_level_controller_name,\n       controller_type: metadata.system_labels.top_level_controller_type], 1d,.mean;\n\n#Get the memory bytes limit\ndef current_memory_limit =\nfetch k8s_container::kubernetes.io/container/memory/limit_bytes\n| group_by [container: resource.container_name,resource.project_id, resource.location, resource.cluster_name,\n       resource.namespace_name, container_name: resource.container_name,\n       controller_name: metadata.system_labels.top_level_controller_name,\n       controller_type: metadata.system_labels.top_level_controller_type], 1d,.mean;\n\n# Get the memory bytes recommendation (QoS: guaranteed)\ndef memory_recommendation = \nfetch k8s_scale::kubernetes.io/autoscaler/container/memory/per_replica_recommended_request_bytes\n| group_by\n      [container: metric.container_name, resource.project_id,\n       resource.location, resource.cluster_name, resource.namespace_name,\n       resource.controller_kind, controller_name: resource.controller_name], sliding(14d), .max\n;\n\n# Join all tables\n{\n@workloads_without_hpa\n;\ncurrent_cpu_request: @current_cpu_request\n;\ncurrent_cpu_limit: @current_cpu_limit\n; \ncontainer_count: @container_count\n;\ncpu_recommendation: @cpu_request_recommendation\n;\nguaranteed_cpu_recommendation: @guaranteed_cpu_request_recommendation\n; \ncurrent_memory_limit: @current_memory_limit\n;\ncurrent_memory_request: @current_memory_request\n;\nmemory_recommendation: @memory_recommendation\n}\n| join\n\n# Map Columns\n|   [\nProject: resource.project_id,\nresource.project_id,\nLocation: resource.location,\nCluster: resource.cluster_name,\nNamespace: resource.namespace_name,\nController_Type: resource.controller_kind,\nController_Name: controller_name,\nContainer_Name: container_name,\nCurrent_Num_Containers: container_count.row_count,\n\n#CPU Columns\nCurrent_CPU_Request_mCPU: int_round(current_cpu_request.value_request_cores_mean_mul),\nCurrent_CPU_Limit_mCPU: int_round(current_cpu_limit),  \nRecommendation_CPU_Request_mCPU: int_round(cpu_request_recommendation),\nRecommendation_CPU_Limit_mCPU: int_round(current_cpu_limit *(cpu_request_recommendation/current_cpu_request)),\nGuaranteed_Rec_CPU_Request_mCPU: int_ceil(guaranteed_cpu_recommendation.value_per_replica_recommended_request_cores_mean_mul),\nGuaranteed_Rec_CPU_Limit_mCPU: int_ceil(current_cpu_limit * (guaranteed_cpu_recommendation.value_per_replica_recommended_request_cores_mean_mul / current_cpu_request)),\n\n#Memory Columns\nCurrent_MEM_Request_MiB: int_round(scale(current_memory_request, 'MiBy')),\nCurrent_MEM_Limit_MiB: int_round(scale(current_memory_limit, 'MiBy')), \nRecommendation_MEM_Request_MiB: int_ceil(scale(memory_recommendation, 'MiBy')),\nRecommendation_MEM_Limit_MiB: int_ceil(scale(current_memory_limit * (memory_recommendation/current_memory_request), 'MiBy'))\n]\n# Set a prioritatizon\n| value [int_round(abs(cast_units((Current_CPU_Request_mCPU - Recommendation_CPU_Request_mCPU), \"\")   + (cast_units((Current_MEM_Request_MiB - Recommendation_MEM_Request_MiB),\"\")* (0.021811/0.002923)) * cast_units(Current_Num_Containers, \"\")))]\n\n"
                }
              }
            ],
            "metricVisualization": "NUMBER"
          },
          "title": "Container Recommendations"
        },
        "width": 12,
        "xPos": 0,
        "yPos": 1
      },
      {
        "height": 1,
        "widget": {
          "text": {
            "content": "This dashboard shows container recommendations at scale and across GCP projects",
            "format": "RAW"
          },
          "title": "GKE Optimization Container Recommendations"
        },
        "width": 12,
        "xPos": 0,
        "yPos": 0
      },
      {
        "height": 8,
        "widget": {
          "collapsibleGroup": {
            "collapsed": false
          },
          "title": "Top 5: Memory and CPU Recommendations"
        },
        "width": 12,
        "xPos": 0,
        "yPos": 7
      },
      {
        "height": 4,
        "widget": {
          "timeSeriesTable": {
            "dataSets": [
              {
                "tableDisplayOptions": {},
                "timeSeriesQuery": {
                  "timeSeriesQueryLanguage": "# Get all workloads using horizontal pod autoscaling(HPA)\ndef all_hpa_workloads =\n  { hpa_cpu:\n      fetch k8s_pod\n      | metric 'custom.googleapis.com/podautoscaler/hpa/cpu/target_utilization'\n      | group_by\n          [resource.project_id, resource.location, resource.cluster_name,\n           resource.namespace_name, controller_name: metric.targetref_name,\n           controller_type: metric.targetref_kind]\n  ; hpa_memory:\n      fetch k8s_pod\n      | metric\n          'custom.googleapis.com/podautoscaler/hpa/memory/target_utilization'\n      | group_by\n          [resource.project_id, resource.location, resource.cluster_name,\n           resource.namespace_name, controller_name: metric.targetref_name,\n           controller_type: metric.targetref_kind] }\n  | outer_join 1, 1\n  | value [has_value: 1];\n\n# Filter out workloads using HPA \ndef workloads_without_hpa =\n  { hpa: @all_hpa_workloads\n  ; workloads:\n      fetch 'k8s_container' :: 'kubernetes.io/container/cpu/request_cores'\n      | group_by\n          [resource.project_id, resource.location, resource.cluster_name,\n           resource.namespace_name,\n           controller_name: metadata.system_labels.top_level_controller_name,\n           controller_type: metadata.system_labels.top_level_controller_type]\n      | value [has_value: 1] }\n  | outer_join 0\n  | filter ((hpa.has_value + workloads.has_value) == 1);\n\n# Get the CPU request cores\ndef current_cpu_request = \nfetch k8s_container::kubernetes.io/container/cpu/request_cores\n  | group_by\n      [container: resource.container_name, resource.project_id, resource.location, resource.cluster_name,\n       resource.namespace_name, container_name: resource.container_name,\n       controller_name: metadata.system_labels.top_level_controller_name,\n       controller_type: metadata.system_labels.top_level_controller_type], 1d, .mean\n       | mul(1000);\n      \n\n# Get the CPU limit cores\ndef current_cpu_limit = \nfetch k8s_container::kubernetes.io/container/cpu/limit_cores\n|group_by [container: resource.container_name, resource.project_id, resource.location, resource.cluster_name,\n       resource.namespace_name, container_name: resource.container_name,\n       controller_name: metadata.system_labels.top_level_controller_name,\n       controller_type: metadata.system_labels.top_level_controller_type], 1d, .mean | mul(1000);\n\n# Get the CPU request core recommendation 95th percentile (QoS: burstable and best effort) \ndef cpu_request_recommendation = \nfetch k8s_scale ::\n    kubernetes.io/autoscaler/container/cpu/per_replica_recommended_request_cores\n  | group_by\n      [container: metric.container_name, resource.project_id,\n       resource.location, resource.cluster_name, resource.namespace_name,\n       resource.controller_kind, controller_name: resource.controller_name], sliding(14d),\n    [cpu_request_recommendation:\n       percentile(value.per_replica_recommended_request_cores, 95) * 1000]\n       ;\n\n# Get the CPU request core recommendation mean (QoS: guaranteed)\ndef guaranteed_cpu_request_recommendation = \nfetch k8s_scale ::\n    kubernetes.io/autoscaler/container/cpu/per_replica_recommended_request_cores\n  | group_by\n      [container: metric.container_name, resource.project_id,\n       resource.location, resource.cluster_name, resource.namespace_name,\n       resource.controller_kind, controller_name: resource.controller_name], sliding(14d), .mean \n       | mul(1000);\n\n# Get the number of containers\ndef container_count = \nfetch k8s_container:: kubernetes.io/container/cpu/request_cores\n  | group_by\n      [container: resource.container_name,resource.project_id, resource.location, resource.cluster_name,\n       resource.namespace_name, container_name: resource.container_name,\n       controller_name: metadata.system_labels.top_level_controller_name,\n       controller_type: metadata.system_labels.top_level_controller_type], 1m,[row_count: row_count()] ;\n\n\n\n# Join all tables\n{\n@workloads_without_hpa\n;\ncurrent_cpu_request: @current_cpu_request\n;\ncurrent_cpu_limit: @current_cpu_limit\n; \ncontainer_count: @container_count\n;\ncpu_recommendation: @cpu_request_recommendation\n;\nguaranteed_cpu_recommendation: @guaranteed_cpu_request_recommendation\n\n}\n| join\n\n# Map Columns\n|   [\nProject: resource.project_id,\nresource.project_id,\nLocation: resource.location,\nCluster: resource.cluster_name,\nNamespace: resource.namespace_name,\nController_Type: resource.controller_kind,\nController_Name: controller_name,\nContainer_Name: container_name,\nCurrent_Num_Containers: container_count.row_count,\n\n#CPU Columns\nCurrent_CPU_Request_mCPU: int_round(current_cpu_request.value_request_cores_mean_mul),\nCurrent_CPU_Limit_mCPU: int_round(current_cpu_limit),  \nRecommendation_CPU_Request_mCPU: int_round(cpu_request_recommendation),\nRecommendation_CPU_Limit_mCPU: int_round(current_cpu_limit *(cpu_request_recommendation/current_cpu_request)),\nGuaranteed_Rec_CPU_Request_mCPU: int_ceil(guaranteed_cpu_recommendation.value_per_replica_recommended_request_cores_mean_mul),\nGuaranteed_Rec_CPU_Limit_mCPU: int_ceil(current_cpu_limit * (guaranteed_cpu_recommendation.value_per_replica_recommended_request_cores_mean_mul / current_cpu_request)),\n\n]\n# Set a prioritatizon\n| value [(Current_CPU_Request_mCPU - Recommendation_CPU_Request_mCPU) * Current_Num_Containers]\n| filter val() > 0\n| top 5\n\n"
                }
              }
            ],
            "metricVisualization": "NUMBER"
          },
          "title": "CPU: Top 5 over-provisioned apps"
        },
        "width": 6,
        "xPos": 0,
        "yPos": 7
      },
      {
        "height": 4,
        "widget": {
          "timeSeriesTable": {
            "dataSets": [
              {
                "tableDisplayOptions": {},
                "timeSeriesQuery": {
                  "timeSeriesQueryLanguage": "# Get all workloads using horizontal pod autoscaling(HPA)\ndef all_hpa_workloads =\n  { hpa_cpu:\n      fetch k8s_pod\n      | metric 'custom.googleapis.com/podautoscaler/hpa/cpu/target_utilization'\n      | group_by\n          [resource.project_id, resource.location, resource.cluster_name,\n           resource.namespace_name, controller_name: metric.targetref_name,\n           controller_type: metric.targetref_kind]\n  ; hpa_memory:\n      fetch k8s_pod\n      | metric\n          'custom.googleapis.com/podautoscaler/hpa/memory/target_utilization'\n      | group_by\n          [resource.project_id, resource.location, resource.cluster_name,\n           resource.namespace_name, controller_name: metric.targetref_name,\n           controller_type: metric.targetref_kind] }\n  | outer_join 1, 1\n  | value [has_value: 1];\n\n# Filter out workloads using HPA \ndef workloads_without_hpa =\n  { hpa: @all_hpa_workloads\n  ; workloads:\n      fetch 'k8s_container' :: 'kubernetes.io/container/cpu/request_cores'\n      | group_by\n          [resource.project_id, resource.location, resource.cluster_name,\n           resource.namespace_name,\n           controller_name: metadata.system_labels.top_level_controller_name,\n           controller_type: metadata.system_labels.top_level_controller_type]\n      | value [has_value: 1] }\n  | outer_join 0\n  | filter ((hpa.has_value + workloads.has_value) == 1);\n\n# Get the CPU request cores\ndef current_cpu_request = \nfetch k8s_container::kubernetes.io/container/cpu/request_cores\n  | group_by\n      [container: resource.container_name, resource.project_id, resource.location, resource.cluster_name,\n       resource.namespace_name, container_name: resource.container_name,\n       controller_name: metadata.system_labels.top_level_controller_name,\n       controller_type: metadata.system_labels.top_level_controller_type], 1d, .mean\n       | mul(1000);\n      \n\n# Get the CPU limit cores\ndef current_cpu_limit = \nfetch k8s_container::kubernetes.io/container/cpu/limit_cores\n|group_by [container: resource.container_name, resource.project_id, resource.location, resource.cluster_name,\n       resource.namespace_name, container_name: resource.container_name,\n       controller_name: metadata.system_labels.top_level_controller_name,\n       controller_type: metadata.system_labels.top_level_controller_type], 1d, .mean | mul(1000);\n\n# Get the CPU request core recommendation 95th percentile (QoS: burstable and best effort) \ndef cpu_request_recommendation = \nfetch k8s_scale ::\n    kubernetes.io/autoscaler/container/cpu/per_replica_recommended_request_cores\n  | group_by\n      [container: metric.container_name, resource.project_id,\n       resource.location, resource.cluster_name, resource.namespace_name,\n       resource.controller_kind, controller_name: resource.controller_name], sliding(14d),\n    [cpu_request_recommendation:\n       percentile(value.per_replica_recommended_request_cores, 95) * 1000]\n       ;\n\n# Get the CPU request core recommendation mean (QoS: guaranteed)\ndef guaranteed_cpu_request_recommendation = \nfetch k8s_scale ::\n    kubernetes.io/autoscaler/container/cpu/per_replica_recommended_request_cores\n  | group_by\n      [container: metric.container_name, resource.project_id,\n       resource.location, resource.cluster_name, resource.namespace_name,\n       resource.controller_kind, controller_name: resource.controller_name], sliding(14d), .mean \n       | mul(1000);\n\n# Get the number of containers\ndef container_count = \nfetch k8s_container:: kubernetes.io/container/cpu/request_cores\n  | group_by\n      [container: resource.container_name,resource.project_id, resource.location, resource.cluster_name,\n       resource.namespace_name, container_name: resource.container_name,\n       controller_name: metadata.system_labels.top_level_controller_name,\n       controller_type: metadata.system_labels.top_level_controller_type], 1m,[row_count: row_count()] ;\n\n\n\n# Join all tables\n{\n@workloads_without_hpa\n;\ncurrent_cpu_request: @current_cpu_request\n;\ncurrent_cpu_limit: @current_cpu_limit\n; \ncontainer_count: @container_count\n;\ncpu_recommendation: @cpu_request_recommendation\n;\nguaranteed_cpu_recommendation: @guaranteed_cpu_request_recommendation\n\n}\n| join\n\n# Map Columns\n|   [\nProject: resource.project_id,\nresource.project_id,\nLocation: resource.location,\nCluster: resource.cluster_name,\nNamespace: resource.namespace_name,\nController_Type: resource.controller_kind,\nController_Name: controller_name,\nContainer_Name: container_name,\nCurrent_Num_Containers: container_count.row_count,\n\n#CPU Columns\nCurrent_CPU_Request_mCPU: int_round(current_cpu_request.value_request_cores_mean_mul),\nCurrent_CPU_Limit_mCPU: int_round(current_cpu_limit),  \nRecommendation_CPU_Request_mCPU: int_round(cpu_request_recommendation),\nRecommendation_CPU_Limit_mCPU: int_round(current_cpu_limit *(cpu_request_recommendation/current_cpu_request)),\nGuaranteed_Rec_CPU_Request_mCPU: int_ceil(guaranteed_cpu_recommendation.value_per_replica_recommended_request_cores_mean_mul),\nGuaranteed_Rec_CPU_Limit_mCPU: int_ceil(current_cpu_limit * (guaranteed_cpu_recommendation.value_per_replica_recommended_request_cores_mean_mul / current_cpu_request)),\n\n]\n# Set a prioritatizon\n| value [(Current_CPU_Request_mCPU - Recommendation_CPU_Request_mCPU) * Current_Num_Containers]\n| filter val() < 0\n| bottom 5\n\n"
                }
              }
            ],
            "metricVisualization": "NUMBER"
          },
          "title": "CPU: Top 5 under-provisioned apps"
        },
        "width": 6,
        "xPos": 6,
        "yPos": 7
      },
      {
        "height": 4,
        "widget": {
          "timeSeriesTable": {
            "dataSets": [
              {
                "tableDisplayOptions": {},
                "timeSeriesQuery": {
                  "timeSeriesQueryLanguage": "def all_hpa_workloads =\n  { hpa_cpu:\n      fetch k8s_pod \n      |metric 'custom.googleapis.com/podautoscaler/hpa/cpu/target_utilization'\n      | every 1m\n      | group_by\n          [resource.project_id, resource.location, resource.cluster_name,\n           resource.namespace_name, controller_name: metric.targetref_name,\n           controller_type: metric.targetref_kind]\n           \n  ; hpa_memory:\n      fetch\n        'k8s_pod' ::\n        'custom.googleapis.com/podautoscaler/hpa/memory/target_utilization'\n      | every 1m\n      | group_by\n          [resource.project_id, resource.location, resource.cluster_name,\n           resource.namespace_name, controller_name: metric.targetref_name,\n           controller_type: metric.targetref_kind]\n            }\n  | union\n  | value [-1]\n  ;\n\ndef workloads_without_hpa = {\nhpa: @all_hpa_workloads\n;\nworkloads: fetch k8s_container::kubernetes.io/container/cpu/request_cores\n  | group_by 1m, [value_request_cores_mean: mean(value.request_cores)]\n  | every 1m\n  | group_by\n      [\n      resource.project_id, \n      resource.location, \n      resource.cluster_name,\n      resource.namespace_name, controller_name: metadata.system_labels.top_level_controller_name,\n       controller_type: metadata.system_labels.top_level_controller_type],\n       [value_request_cores_mean: mean(value_request_cores_mean)]\n    \n    | value [1]\n\n} \n| outer_join 0\n| filter(hpa.int_lit + workloads.int_lit == 1)\n;\n\n\ndef container_count = \nfetch k8s_container:: kubernetes.io/container/cpu/request_cores\n  | group_by 1m, [row_count: row_count()]\n  | every 1m\n  | group_by\n      [container: resource.container_name,resource.project_id, resource.location, resource.cluster_name,\n       resource.namespace_name, container_name: resource.container_name,\n       controller_name: metadata.system_labels.top_level_controller_name,\n       controller_type: metadata.system_labels.top_level_controller_type],[row_count: row_count()]    \n;\n\ndef current_memory_request = \nfetch k8s_container::kubernetes.io/container/memory/request_bytes\n| group_by 1m, [value_request_bytes_max: max(value.request_bytes)]\n| every 1m\n| group_by\n      [container: resource.container_name,resource.project_id, resource.location, resource.cluster_name,\n       resource.namespace_name, container_name: resource.container_name,\n       controller_name: metadata.system_labels.top_level_controller_name,\n       controller_type: metadata.system_labels.top_level_controller_type],\n    [current_memory_request: max(value_request_bytes_max)/1024/1024]\n;\n\ndef current_memory_limit =\nfetch k8s_container::kubernetes.io/container/memory/limit_bytes\n| group_by 1m, [value_limit_bytes_max: max(value.limit_bytes)]\n| every 1m\n| group_by [container: resource.container_name,resource.project_id, resource.location, resource.cluster_name,\n       resource.namespace_name, container_name: resource.container_name,\n       controller_name: metadata.system_labels.top_level_controller_name,\n       controller_type: metadata.system_labels.top_level_controller_type], [current_memory_limit: max(value_limit_bytes_max)/1024/1024] \n;\ndef memory_recommendation = \nfetch k8s_scale\n| metric\n    'kubernetes.io/autoscaler/container/memory/per_replica_recommended_request_bytes'\n| group_by 1m, [value_per_replica_recommended_request_bytes_max:\n       max(value.per_replica_recommended_request_bytes)]\n| group_by\n      [container: metric.container_name, resource.project_id,\n       resource.location, resource.cluster_name, resource.namespace_name,\n       resource.controller_kind, controller_name: resource.controller_name],\n    [memory_recommendation:\n       max(value_per_replica_recommended_request_bytes_max)/1024/1024]\n| within 14d\n;\n{\n@workloads_without_hpa\n;\ncontainer_count: @container_count\n; \ncurrent_memory_limit: @current_memory_limit\n;\ncurrent_memory_request: @current_memory_request\n;\nmemory_recommendation: @memory_recommendation\n}\n| join\n|within(14d)\n|  map [\nProject: resource.project_id,\nresource.project_id,\nLocation: resource.location,\nCluster: resource.cluster_name,\nNamespace: resource.namespace_name,\nController_Type: resource.controller_kind,\nController_Name: controller_name,\nContainer_Name: container_name,\nCurrent_Num_Containers: container_count.row_count,\n\n#Memory Columns\nCurrent_MEM_Request_MiB: int_ceil(current_memory_request),\nCurrent_MEM_Limit_MiB: int_ceil(current_memory_limit), \nRecommendation_MEM_Request_MiB: int_ceil(memory_recommendation),\nRecommendation_MEM_Limit_MiB: int_ceil(current_memory_limit * (memory_recommendation/current_memory_request))\n]\n\n| value [(Current_MEM_Request_MiB - Recommendation_MEM_Request_MiB) * Current_Num_Containers]\n| filter val() > 0\n| top 5"
                }
              }
            ],
            "metricVisualization": "NUMBER"
          },
          "title": "Memory: Top 5 over-provisioned apps"
        },
        "width": 6,
        "xPos": 0,
        "yPos": 11
      },
      {
        "height": 4,
        "widget": {
          "timeSeriesTable": {
            "dataSets": [
              {
                "tableDisplayOptions": {},
                "timeSeriesQuery": {
                  "timeSeriesQueryLanguage": "def all_hpa_workloads =\n  { hpa_cpu:\n      fetch k8s_pod \n      |metric 'custom.googleapis.com/podautoscaler/hpa/cpu/target_utilization'\n      | every 1m\n      | group_by\n          [resource.project_id, resource.location, resource.cluster_name,\n           resource.namespace_name, controller_name: metric.targetref_name,\n           controller_type: metric.targetref_kind]\n           \n  ; hpa_memory:\n      fetch\n        'k8s_pod' ::\n        'custom.googleapis.com/podautoscaler/hpa/memory/target_utilization'\n      | every 1m\n      | group_by\n          [resource.project_id, resource.location, resource.cluster_name,\n           resource.namespace_name, controller_name: metric.targetref_name,\n           controller_type: metric.targetref_kind]\n            }\n  | union\n  | value [-1]\n  ;\n\ndef workloads_without_hpa = {\nhpa: @all_hpa_workloads\n;\nworkloads: fetch k8s_container::kubernetes.io/container/cpu/request_cores\n  | group_by 1m, [value_request_cores_mean: mean(value.request_cores)]\n  | every 1m\n  | group_by\n      [\n      resource.project_id, \n      resource.location, \n      resource.cluster_name,\n      resource.namespace_name, controller_name: metadata.system_labels.top_level_controller_name,\n       controller_type: metadata.system_labels.top_level_controller_type],\n       [value_request_cores_mean: mean(value_request_cores_mean)]\n    \n    | value [1]\n\n} \n| outer_join 0\n| filter(hpa.int_lit + workloads.int_lit == 1)\n;\n\n\ndef container_count = \nfetch k8s_container:: kubernetes.io/container/cpu/request_cores\n  | group_by 1m, [row_count: row_count()]\n  | every 1m\n  | group_by\n      [container: resource.container_name,resource.project_id, resource.location, resource.cluster_name,\n       resource.namespace_name, container_name: resource.container_name,\n       controller_name: metadata.system_labels.top_level_controller_name,\n       controller_type: metadata.system_labels.top_level_controller_type],[row_count: row_count()]    \n;\n\ndef current_memory_request = \nfetch k8s_container::kubernetes.io/container/memory/request_bytes\n| group_by 1m, [value_request_bytes_max: max(value.request_bytes)]\n| every 1m\n| group_by\n      [container: resource.container_name,resource.project_id, resource.location, resource.cluster_name,\n       resource.namespace_name, container_name: resource.container_name,\n       controller_name: metadata.system_labels.top_level_controller_name,\n       controller_type: metadata.system_labels.top_level_controller_type],\n    [current_memory_request: max(value_request_bytes_max)/1024/1024]\n;\n\ndef current_memory_limit =\nfetch k8s_container::kubernetes.io/container/memory/limit_bytes\n| group_by 1m, [value_limit_bytes_max: max(value.limit_bytes)]\n| every 1m\n| group_by [container: resource.container_name,resource.project_id, resource.location, resource.cluster_name,\n       resource.namespace_name, container_name: resource.container_name,\n       controller_name: metadata.system_labels.top_level_controller_name,\n       controller_type: metadata.system_labels.top_level_controller_type], [current_memory_limit: max(value_limit_bytes_max)/1024/1024] \n;\ndef memory_recommendation = \nfetch k8s_scale\n| metric\n    'kubernetes.io/autoscaler/container/memory/per_replica_recommended_request_bytes'\n| group_by 1m, [value_per_replica_recommended_request_bytes_max:\n       max(value.per_replica_recommended_request_bytes)]\n| group_by\n      [container: metric.container_name, resource.project_id,\n       resource.location, resource.cluster_name, resource.namespace_name,\n       resource.controller_kind, controller_name: resource.controller_name],\n    [memory_recommendation:\n       max(value_per_replica_recommended_request_bytes_max)/1024/1024]\n| within 14d\n;\n{\n@workloads_without_hpa\n;\ncontainer_count: @container_count\n; \ncurrent_memory_limit: @current_memory_limit\n;\ncurrent_memory_request: @current_memory_request\n;\nmemory_recommendation: @memory_recommendation\n}\n| join\n|within(14d)\n|  map [\nProject: resource.project_id,\nresource.project_id,\nLocation: resource.location,\nCluster: resource.cluster_name,\nNamespace: resource.namespace_name,\nController_Type: resource.controller_kind,\nController_Name: controller_name,\nContainer_Name: container_name,\nCurrent_Num_Containers: container_count.row_count,\n\n#Memory Columns\nCurrent_MEM_Request_MiB: int_ceil(current_memory_request),\nCurrent_MEM_Limit_MiB: int_ceil(current_memory_limit), \nRecommendation_MEM_Request_MiB: int_ceil(memory_recommendation),\nRecommendation_MEM_Limit_MiB: int_ceil(current_memory_limit * (memory_recommendation/current_memory_request))\n]\n\n| value [(Current_MEM_Request_MiB - Recommendation_MEM_Request_MiB) * Current_Num_Containers]\n| filter val() < 0\n| bottom 5"
                }
              }
            ],
            "metricVisualization": "NUMBER"
          },
          "title": "Memory: Top 5 under-provisioned apps"
        },
        "width": 6,
        "xPos": 6,
        "yPos": 11
      }
    ]
  }
}
